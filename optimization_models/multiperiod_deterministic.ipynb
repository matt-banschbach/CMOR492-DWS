{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T20:02:05.447672Z",
     "start_time": "2025-02-19T20:02:05.424834Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "#   If you are getting ModuleNotFoundError, uncomment the following line...\n",
    "import sys\n",
    "#   ...and then replace 'your_path' with your path to this CMOR492-DWS directory\n",
    "#       (if you're pulling from the github, the directory is called CMOR492-DWS as of 19/02/2025)\n",
    "# sys.path.append('your_path/CMOR492-DWS')\n",
    "# sys.path.append('/Users/danielsuarez/Documents/Academic/Spring2025/SeniorDesign/CMOR492-DWS/')\n",
    "sys.path.append(\"C:\\\\Users\\\\gabri\\\\Documents\\\\CMOR492-DWS\") # This is the path on Gabriel Lundquist's machine.\n",
    "from network_construction.network import source_treatment, get_Utown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2114a07669a9391",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T20:02:06.261066Z",
     "start_time": "2025-02-19T20:02:06.175395Z"
    }
   },
   "outputs": [],
   "source": [
    "G = get_Utown()\n",
    "# Grab the source nodes and treatment nodes off the existing graph\n",
    "source_nodes, treatment_nodes = source_treatment(G)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e133f38e4866f8fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T20:02:09.092485Z",
     "start_time": "2025-02-19T20:02:06.915438Z"
    }
   },
   "outputs": [],
   "source": [
    "### MODEL PARAMETERS\n",
    "\n",
    "# TODO: What if we just make pipe size continuous/linear\n",
    "\n",
    "Path = {}  # Set of shortest paths from each source node i to each treatment node j\n",
    "NLinks = {}  # Number of edges in each path\n",
    "L = {}  # Length of each path (distance)\n",
    "\n",
    "for i in source_nodes:\n",
    "    for j in treatment_nodes:\n",
    "        path = nx.shortest_path(G, source=i, target=j, weight='length')\n",
    "        Path[i, j] = path\n",
    "        NLinks[i, j] = len(path)-1\n",
    "        L[i, j] = nx.path_weight(G, path, weight='length')\n",
    "LE = {e: G.edges[e]['length'] for e in G.edges}  # Length of edge e\n",
    "EL = {v: G.nodes[v]['elevation'] for v in G.nodes}  # Elevation of node v\n",
    "\n",
    "\n",
    "D = [0.2, 0.25, 0.3, 0.35, 0.40, 0.45]  # Pipe diameters\n",
    "CP = {0.05: 8.7, 0.06: 9.5, 0.08: 11,\n",
    "                       0.1: 12.6, 0.15: 43.5, 0.2: 141,\n",
    "                       0.25: 151, 0.3: 161, 0.35: 180,\n",
    "                       0.4: 190, 0.45: 200}  # Cost per unit of pipe\n",
    "\n",
    "\n",
    "SR = {}  # Production at Source node i\n",
    "CAP = {}  # Capacity at treatment node j\n",
    "\n",
    "for node in source_nodes:\n",
    "    G.nodes[node]['production'] = .17\n",
    "    SR[node] = .17\n",
    "\n",
    "total_flow = sum(SR.values())\n",
    "\n",
    "for node in treatment_nodes:\n",
    "    G.nodes[node]['capacity'] = 1000\n",
    "    CAP[node] = 1000\n",
    "\n",
    "Vmin = 0.6 * 60\n",
    "Vmax = 3 * 60\n",
    "\n",
    "CE = 25  # Cost of Excavation\n",
    "CB = 6  # Cost of Bedding\n",
    "TR = 44000  # Fixed Cost of Treatment Plant\n",
    "TRFlow = 100  # Variable Cost of Treatment\n",
    "PICost = 30\n",
    "\n",
    "PF = {'0.05': 8.7, '0.06': 9.5, '0.08': 11,\n",
    "                       '0.1': 12.6, '0.15': 43.5, '0.2': 141,\n",
    "                       '0.25': 151, '0.3': 161, '0.35': 180,\n",
    "                       '0.4': 190, '0.45': 200}  # Fixed Cost of Piping\n",
    "\n",
    "CT = 1000000000  # Cost of trucking\n",
    "M = 1e6\n",
    "\n",
    "Smin = 0.01\n",
    "Smax = 0.1\n",
    "W = 0.5  # Buffer Width\n",
    "\n",
    "R = 0  # Discount factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991500d7d60d1e36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T20:02:10.504103Z",
     "start_time": "2025-02-19T20:02:09.114701Z"
    }
   },
   "outputs": [],
   "source": [
    "m = gp.Model()\n",
    "\n",
    "### DECISION VARIABLES\n",
    "\n",
    "x = m.addVars(Path.keys(), vtype=GRB.BINARY, name='x')  # Path ij used \n",
    "y = m.addVars(treatment_nodes, vtype=GRB.BINARY, name='y')  # treatment at node j \n",
    "z = m.addVars(G.edges, vtype=GRB.BINARY, name='z')  # edge e used\n",
    "\n",
    "\n",
    "\n",
    "# v This v is added in ### ADD DECISION VARIABLES FOR MULTIPERIOD\n",
    "# d = m.addVars(G.edges, D, vtype=GRB.BINARY, name='d')  # New replacement pipe size s at edge e \n",
    "\n",
    "a = m.addVars(G.edges, D, vtype=GRB.BINARY, name='a')  # Pipe size s at edge e \n",
    "\n",
    "# Node Elevation\n",
    "el = m.addVars(G.nodes, vtype=GRB.CONTINUOUS, name='el')  # Elevation at node v \n",
    "\n",
    "# Recourse Amount\n",
    "r = m.addVars(source_nodes, vtype=GRB.CONTINUOUS, lb=0.0, name='r')  # Flow handled by trucking at edge e \n",
    "\n",
    "# Flow in Edge e\n",
    "Q = m.addVars(G.edges, vtype=GRB.CONTINUOUS, lb=0.0, name='Q')  # Flow in Edge e \n",
    "\n",
    "# Path Flow\n",
    "p = m.addVars(Path.keys(), vtype=GRB.CONTINUOUS, lb = 0.0, name='p')  # Flow through path ij \n",
    "\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cb025c15dc02c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T20:02:47.719445Z",
     "start_time": "2025-02-19T20:02:32.631435Z"
    }
   },
   "outputs": [],
   "source": [
    "### CONSTRAINTS (single period; see below for multiperiod)\n",
    "\n",
    "# NODE PRODUCTION MINUS RECOURSE\n",
    "node_prod_rec = m.addConstrs((p[i, j] >= (SR[i] * x[i, j]) - r[i] for i, j in Path.keys()), name='node_prod_rec')\n",
    "\n",
    "# TREATMENT CAPACITY\n",
    "treat_cap = m.addConstrs((gp.quicksum(p[i, j] for i in source_nodes) <= CAP[j] * y[j] for j in treatment_nodes), name='treat_cap')\n",
    "\n",
    "#  NODE ASSIGNMENT\n",
    "node_assign = m.addConstrs((gp.quicksum(x[i, j] for j in treatment_nodes) == 1 for i in source_nodes), name='node_assign')\n",
    "\n",
    "# PIPE SIZING\n",
    "pipe_sizing = m.addConstrs((gp.quicksum(a[*e, s] for s in D) == z[e] for e in G.edges), name='pipe_sizing')  # ALWAYS BE SURE TO UNPACK e\n",
    "\n",
    "# TODO: Go through this with John\n",
    "# FLOW DEFINITION\n",
    "def is_sublist(short_list, long_list):\n",
    "    for i in range(len(long_list) - len(short_list) + 1):\n",
    "        if long_list[i:i + len(short_list)] == short_list:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "flow_def = m.addConstrs((Q[e] == gp.quicksum(p[i, j] for i, j in Path.keys() if is_sublist(list((e[0], e[1])),Path[i,j])) for e in G.edges), name='flow_def')\n",
    "\n",
    "\n",
    "# MIN/MAX SLOPE\n",
    "min_slope = m.addConstrs((el[e[0]] - el[e[1]] >= (LE[e] * Smin) - (M * (1 - z[e])) for e in G.edges), name='min_slope')\n",
    "max_slope = m.addConstrs((el[e[0]] - el[e[1]] <= (LE[e] * Smax) + (M * (1 - z[e])) for e in G.edges), name='max_slope')\n",
    "\n",
    "# FLOW VELOCITY LIMIT\n",
    "flow_vel = m.addConstrs((Q[e] <= Vmax * gp.quicksum((np.pi / 8) * (s**2) * (a[*e, s]) for s in D) for e in G.edges), name='flow_vel')\n",
    "\n",
    "# PIPES UNDERGROUND\n",
    "underground = m.addConstrs((el[u] <= EL[u] for u in G.nodes), name='underground')\n",
    "m.update()\n",
    "# EDGE ACTIVATION\n",
    "\n",
    "# TODO: Go through this with John 2\n",
    "# EDGE ACTIVATION\n",
    "ePath = {}  # Use this for Edge Activation Constraint\n",
    "for e, p_ in Path.items(): # Using temporary variable p_ since p is already a decision variable (see above)\n",
    "    ePath[e] = [(p_[l - 1], p_[l]) for l in range(1, len(p_))]\n",
    "\n",
    "edge_activate = m.addConstrs((gp.quicksum(z[e] for e in ePath[i, j]) >= NLinks[i, j] * x[i, j] for i, j in Path), name='edge_activate')\n",
    "\n",
    "\n",
    "# ENVELOPES FOR MANNING\n",
    "\n",
    "T = 11.9879\n",
    "P = lambda LE, s: LE / (T * (s**(16/3)))\n",
    "Qmax = lambda s: Vmax * ((np.pi / 8) * (s**2))\n",
    "\n",
    "\n",
    "alpha = m.addVars(G.edges, D, lb=0, name='alpha')\n",
    "beta = m.addVars(G.edges, D, lb=0, name='beta')\n",
    "\n",
    "\n",
    "alpha_2 = m.addConstrs((alpha[*e, s] >= Q[e] + a[*e, s] * Qmax(s) - ( Qmax(s)) for e in G.edges for s in D), name='alpha_2')\n",
    "alpha_3 = m.addConstrs((alpha[*e, s] <= Qmax(s) * a[*e, s] for e in G.edges for s in D), name='alpha_3')\n",
    "alpha_4 = m.addConstrs((alpha[*e, s] <= Q[e] for e in G.edges for s in D), name='alpha_4')\n",
    "alpha_5 = m.addConstrs((alpha[*e, s] <= Qmax(s) for e in G.edges for s in D), name='alpha_5')\n",
    "\n",
    "beta_2 = m.addConstrs((beta[*e, s] >= (Qmax(s) * Q[e]) + (Qmax(s) * alpha[*e, s]) - (Qmax(s)**2) for e in G.edges for s in D), name='beta_2')\n",
    "beta_3 = m.addConstrs((beta[*e, s] <= Qmax(s) * alpha[*e, s] for e in G.edges for s in D), name='beta_3')\n",
    "beta_4 = m.addConstrs((beta[*e, s] <= Qmax(s) * Q[e] for e in G.edges for s in D), name='beta_4')\n",
    "\n",
    "# manning_2 = m.addConstrs((el[e[1]] - el[e[0]] + gp.quicksum(P(LE[e], s) * beta[*e, s] for s in D) <= 0 for e in G.edges), name='manning_2')\n",
    "\n",
    "# ADDED THE BIG M THING HERE BUT IDK IF IT COULD BE IMPROVED\n",
    "manning_2 = m.addConstrs((el[e[1]] - el[e[0]] + gp.quicksum(P(LE[e], s) * beta[*e, s] for s in D) <= (1-z[e])*M for e in G.edges), name='manning_2')\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e128e26dde19055",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T20:02:59.467826Z",
     "start_time": "2025-02-19T20:02:59.457337Z"
    }
   },
   "outputs": [],
   "source": [
    "# OBJECTIVE EPXR 1: TREATMENT COSTS\n",
    "treat_cost = gp.LinExpr()\n",
    "for j in treatment_nodes:\n",
    "    treat_cost.addTerms(TR, y[j])\n",
    "    for i in source_nodes:\n",
    "        treat_cost.addTerms(TRFlow * SR[i], x[i, j])\n",
    "\n",
    "# OBJECTIVE EXPR 2: EXCAVATION COSTS\n",
    "excav_cost_f = lambda u, v: gp.QuadExpr(CE * (((EL[u] - el[u]) + (EL[v] - el[v])) / 2) * LE[u, v] * gp.quicksum(s + ((2*W) * a[u, v, s]) for s in D))\n",
    "\n",
    "# OBJECTIVE EXPR 3: BEDDING COSTS\n",
    "bed_cost_f = lambda u, v: gp.LinExpr(CB * LE[u, v] * gp.quicksum(s + ((2*W) * a[u, v, s]) for s in D))\n",
    "# OBJECTIVE EXPR 4: PIPE COSTS\n",
    "pipe_cost_f = lambda u, v: gp.LinExpr(LE[u, v] * gp.quicksum(CP[s] * a[u, v, s] for s in D))\n",
    "\n",
    "excav_bed_cost = gp.quicksum(excav_cost_f(u, v) + bed_cost_f(u, v) + pipe_cost_f(u, v) for u, v in G.edges)\n",
    "\n",
    "# OBJECTIVE EXPR 5: RECOURSE TRUCKING\n",
    "\n",
    "rec_cost = gp.LinExpr()\n",
    "for i in source_nodes:\n",
    "    rec_cost.addTerms(CT, r[i])\n",
    "\n",
    "m.setObjective(treat_cost + excav_bed_cost + rec_cost, GRB.MINIMIZE)\n",
    "\n",
    "# m.setObjective(0, GRB.MINIMIZE)\n",
    "\n",
    "m.update()\n",
    "print(f\"Model has {m.NumVars} variables and {m.NumConstrs} constraints.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cddf5b0cdf99f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T20:03:03.287282Z",
     "start_time": "2025-02-19T20:03:01.341496Z"
    }
   },
   "outputs": [],
   "source": [
    "# m.write(\"singleperiod_nocontext2.lp\")\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8305fe1",
   "metadata": {},
   "source": [
    "##### Here begins multiperiod work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa9ce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initializing multiperiod-related variables\n",
    "n_periods = 3\n",
    "periods = list(range(n_periods)) # `periods` can be an arbitrary list/tuple, here we just make it (0,1,2)\n",
    "# v this v is shorthand for creating historical dictionaries for each decision variable (wrap this in function?)\n",
    "(xt, yt, zt, at, elt, rt, Qt, pt) = [{period: None for period in periods} for _ in (x,y,z,a,el,r,Q,p)] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad337c0",
   "metadata": {},
   "source": [
    "##### Problems with modifying and adding constraints: \n",
    "1. When you add or modify a constraint, on model update it clears out the values of the variables, which causes the values of the historical dictionaries to change, if they're just copies of the `tupledict` returned by the constraint initialization functions.\n",
    "2. Setting the `\"rhs\"` attribute on constraints requires a `double` argument, not an argument with `Gurobi.var` variables. \n",
    "\n",
    "##### Solution: \n",
    "1. Manually perform a deeper copy of the `tupledict`, storing keys and values rather than `Gurobi.var` variables\n",
    "2. Manually remove and re-add the modified constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4852cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ONLY RUN FOR AN EXAMPLE OF MODEL UPDATING CLEARING THE VALUES OF THE GUROBI VARIABLES\n",
    "print(f\"{x = }\")\n",
    "d = m.addVars(G.edges, D, vtype=GRB.BINARY, name='d')\n",
    "m.update()\n",
    "print(f\"{x = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4423f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the value of each decision variable in the first period into the historical dictionaries\n",
    "# Can't just call `x.copy()` for example, since that's a shallow copy so the values in the historical dict will change\n",
    "def record_history(period_to_record):\n",
    "    \"\"\" \n",
    "    Write the value of each decision variable in the given period into the \n",
    "    already-declared historical dictionaries. The decision variables are \n",
    "    Gurobi variables, whereas the historical dictionaries are simple \n",
    "    {key : float} pairs for the value of each decision variable after \n",
    "    optimization.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    period_to_record : any\n",
    "    The key for the current period, used to index into the historical dictionaries\n",
    "    \"\"\"\n",
    "\n",
    "    for gurobi_var_dict, history_dict in ((x,xt), \n",
    "                                          (y,yt), \n",
    "                                          (z,zt), \n",
    "                                          (a,at), \n",
    "                                          (el,elt), \n",
    "                                          (r,rt), \n",
    "                                          (Q,Qt), \n",
    "                                          (p,pt)):\n",
    "        # Shorthand. For example, \n",
    "        history_dict[period_to_record] = {key: gurobi_var.X for key, gurobi_var in gurobi_var_dict.items()}\n",
    "\n",
    "record_history(periods[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b824afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE WASTEWATER FLOW\n",
    "for node in source_nodes:\n",
    "    # Arbitrary choice of new wastewater flow for testing purposes\n",
    "    SR[node] = .34\n",
    "    # G.nodes[node]['production'] = .34 # This variable isn't used anywhere else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef6366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADD DECISION VARIABLES AND CONSTRAINTS FOR MULTIPERIOD\n",
    "\n",
    "current_period_index = 1\n",
    "\n",
    "## New variables \n",
    "# What new size pipe needs to be installed, if any\n",
    "d = m.addVars(G.edges, D, vtype=GRB.BINARY, name='d')\n",
    "\n",
    "# Whether elevation at vertex v changes\n",
    "c = m.addVars(G.nodes, vtype=GRB.BINARY, name='c') \n",
    "\n",
    "\n",
    "## New, non-time-dependent constraints\n",
    "# CHANGE IN PIPE SIZE (ensures that at most 1 new pipe size can be selected)\n",
    "pipe_size_change = m.addConstrs((gp.quicksum(d[*e, s] for s in D) <= 1 for e in G.edges), name='pipe_size_change')  \n",
    "# Always unpack e, because the Gurobi tupledicts are indexed by scalar variables, not tuples. \n",
    "# You need [e0, e1, s], not [(e0,e1),s]\n",
    "\n",
    "# VERTEX ELEVATION CHANGE ASSIGNMENT\n",
    "elevation_change_assignment = m.addConstrs(\n",
    "    (gp.quicksum(d[*e, s] for s in D) >= 0.5 * (c[e[0]] + c[e[1]]) + (z[*e] - 1) for e in G.edges), name='elevation_change_assignment')\n",
    "\n",
    "# a-CONSTRAINT (ensures that a truly represents the accurate pipe size)\n",
    "a_constraint = m.addConstrs(\n",
    "    (a[*e, s] <= (d[*e, s] + at[periods[current_period_index-1]][*e, s]) for e in G.edges for s in D), name='a_constraint')\n",
    "# We have to remove ^ this ^ constraint and re-add it after every period, because the numbers from the previous period will change\n",
    "\n",
    "# VERTEX ELEVATION CHANGE ENFORCEMENT\n",
    "max_elevation_change_enforcement = m.addConstrs(\n",
    "    (c[u] >= (el[u] - elt[periods[current_period_index-1]][u]) / M for u in G.nodes), name='max_elevation_change_enforcement')\n",
    "# We have to remove ^ this ^ constraint and re-add it after every period, because the numbers from the previous period will change\n",
    "min_elevation_change_enforcement = m.addConstrs(\n",
    "    (c[u] >= (elt[periods[current_period_index-1]][u] - el[u]) / M for u in G.nodes), name='min_elevation_change_enforcement')\n",
    "# We have to remove ^ this ^ constraint and re-add it after every period, because the numbers from the previous period will change\n",
    "\n",
    "# TREATMENT PLANT CONTINUITY\n",
    "treatment_plant_continuity = m.addConstrs((y[j] >= yt[periods[current_period_index-1]][j] for j in treatment_nodes), name='treatment_plant_continuity')\n",
    "# We have to remove ^ this ^ constraint and re-add it after every period, because the numbers from the previous period will change\n",
    "\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d2cc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EDIT CONSTRAINTS BEFORE STARTING NEW PERIOD\n",
    "# REMOVES PREVIOUS CONSTRAINTS; YOU'LL FIND HANDLES TO THE NEW ONES RETURNED BY THIS METHOD\n",
    "# We *could* just use the global keyword... but I'd like this function to be at least a little portable.\n",
    "# It does still rely on lots of global variables\n",
    "def edit_constrs_SR_change(current_period_index):\n",
    "    # Because the \"rhs\" attribute on constraints requires a double value, not a gurobi.Var, \n",
    "    # we have to manually remove and re-add the constraints. \n",
    "\n",
    "    # NODE PRODUCTION MINUS RECOURSE (depends on modified wastewater flow SR)\n",
    "    m.remove(node_prod_rec)\n",
    "    # The _new emphasizes that this is a temporary, local variable that needs to be returned\n",
    "    node_prod_rec_new = m.addConstrs((p[i, j] >= (SR[i] * x[i, j]) - r[i] for i, j in Path.keys()), name='node_prod_rec')\n",
    "\n",
    "    # a-CONSTRAINT (depends on `a` from previous period)\n",
    "    m.remove(a_constraint)\n",
    "    a_constraint_new = m.addConstrs(\n",
    "        (a[*e, s] <= (d[*e, s] + at[periods[current_period_index-1]][*e, s]) for e in G.edges for s in D), name='a_constraint')\n",
    "    \n",
    "    # VERTEX ELEVATION CHANGE (depends on elevation at previous period)\n",
    "    m.remove(max_elevation_change_enforcement)\n",
    "    m.remove(min_elevation_change_enforcement)\n",
    "    max_elevation_change_enforcement_new = m.addConstrs(\n",
    "        (c[u] >= (el[u] - elt[periods[current_period_index-1]][u]) / M for u in G.nodes), name='max_elevation_change_enforcement')\n",
    "    min_elevation_change_enforcement_new = m.addConstrs(\n",
    "        (c[u] >= (elt[periods[current_period_index-1]][u] - el[u]) / M for u in G.nodes), name='min_elevation_change_enforcement')\n",
    "\n",
    "    # TREATMENT PLANT CONTINUITY (depends on treatment plant existence in previous period)\n",
    "    m.remove(treatment_plant_continuity)\n",
    "    treatment_plant_continuity_new = m.addConstrs(\n",
    "        (y[j] >= yt[periods[current_period_index-1]][j] for j in treatment_nodes), name='treatment_plant_continuity')\n",
    "\n",
    "    return (node_prod_rec_new, a_constraint_new, max_elevation_change_enforcement_new, min_elevation_change_enforcement_new, \n",
    "            treatment_plant_continuity_new)\n",
    "\n",
    "(node_prod_rec, a_constraint, max_elevation_change_enforcement, min_elevation_change_enforcement, \n",
    " treatment_plant_continuity) = edit_constrs_SR_change(current_period_index)\n",
    "print(f\"{current_period_index = }\")\n",
    "\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eb0107",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE OBJECTIVE FUNCTION FOR MULTIPERIOD\n",
    "\n",
    "# OBJECTIVE EPXR 1: add consideration of previous y_j to treatment costs\n",
    "# Treatment cost term in objective function depends on wastewater flow\n",
    "# Easiest to just reinitialize treat_cost rather than combing out the terms depending on previous SR\n",
    "def edit_treatment_cost(current_period_index):\n",
    "    treat_cost_new = gp.LinExpr()\n",
    "    for j in treatment_nodes:\n",
    "        treat_cost_new.add(y[j], TR)\n",
    "        treat_cost_new.addConstant(-TR * yt[periods[current_period_index-1]][j])\n",
    "        for i in source_nodes:\n",
    "            treat_cost_new.add(x[i, j], TRFlow * SR[i])\n",
    "    return treat_cost_new\n",
    "\n",
    "    # All other objective expressions stay the same\n",
    "\n",
    "treat_cost = edit_treatment_cost(current_period_index)\n",
    "\n",
    "# Modify the objective to account for the new treatment cost and discount factor\n",
    "m.setObjective((treat_cost + excav_bed_cost + rec_cost) / (1 + R)**periods[current_period_index], GRB.MINIMIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd7ea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.setObjective(0, GRB.MINIMIZE)\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9344c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5f06a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134084f479529b4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T16:33:43.034902Z",
     "start_time": "2025-02-19T16:33:43.015191Z"
    }
   },
   "outputs": [],
   "source": [
    "for v in r:\n",
    "    if r[v].X > 0:\n",
    "        print(r[v].VarName, r[v].X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ecb3087a950124",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.computeIIS()\n",
    "\n",
    "for c in m.getConstrs():\n",
    "    if c.IISConstr:\n",
    "        print(f\"Constraint {c.ConstrName} is in the IIS\")\n",
    "\n",
    "for v in m.getVars():\n",
    "    if v.IISLB > 0:\n",
    "        print(f\"Lower bound of {v.VarName} is in the IIS\")\n",
    "    elif v.IISUB > 0:\n",
    "        print(f\"Upper bound of {v.VarName} is in the IIS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d1714a911526cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T19:23:22.112034Z",
     "start_time": "2025-02-19T19:23:22.031006Z"
    }
   },
   "outputs": [],
   "source": [
    "x_0 = {str(xv) : x[xv].X for xv in x}\n",
    "y_0 = {yv : y[yv].X for yv in y}\n",
    "z_0 = {str(zv) : z[zv].X for zv in z}\n",
    "\n",
    "d_0 = {str(dv) : a[dv].X for dv in a}\n",
    "el_0 = {elv: el[elv].X for elv in el}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8332415e2e39335",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T19:10:37.046131Z",
     "start_time": "2025-02-19T19:10:37.039587Z"
    }
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940a516819c176fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T19:10:37.756978Z",
     "start_time": "2025-02-19T19:10:37.716926Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"x_sol.json\", \"w\") as f:\n",
    "    json.dump(x_0, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80f3c01961e4550",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T19:23:27.413479Z",
     "start_time": "2025-02-19T19:23:27.380929Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"z_sol.json\", \"w\") as f:\n",
    "    json.dump(z_0, f)\n",
    "\n",
    "with open(\"d_sol.json\", \"w\") as f:\n",
    "    json.dump(d_0, f)\n",
    "\n",
    "with open(\"el_sol.json\", \"w\") as f:\n",
    "    json.dump(el_0, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c953a80f0a09e9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMOR492-DWS_venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
